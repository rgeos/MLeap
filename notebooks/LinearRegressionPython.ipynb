{"cells":[{"cell_type":"markdown","source":["# Linear Regression using ![LOGO](http://demo.epigno.systems/python_spark.png)\n\nIn this notebook we will will employ a simple linear regression model to predict the amount of energy output of a power plant. The dataset used for this analysis comes from [UC Irvine machine learning repository](http://mlr.cs.umass.edu/ml/datasets/Combined+Cycle+Power+Plant). The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011).\n\n**Data information** as described on the site above:\n\nFeatures consist of hourly average ambient variables \n- Temperature (T) in the range 1.81C and 37.11C,\n- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n- Relative Humidity (RH) in the range 25.56% to 100.16%\n- Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg\n- Net hourly electrical energy output (EP) 420.26-495.76 MW\nThe averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization.\n\nThe original headers were renamed as below:\n- T  -> temperature\n- V  -> exhaust\\_vacuum\n- AP -> ambient\\_pressure\n- RH -> relative\\_humidity\n- EP -> energy\\_output\n\nOur goal is to predict the `energy_output` (label) based on the other four features.\n\nAlternative data [Link](http://www.caiso.com/Pages/TodaysOutlook.aspx#SupplyandDemand)"],"metadata":{}},{"cell_type":"code","source":["# importing the necessary libraries\n\nfrom pyspark.ml.regression import LinearRegression as LR\nfrom pyspark.ml.feature import VectorAssembler as VA\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# the data\nfile_name = \"/FileStore/tables/6zm535q61494044083775/data.csv\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# loading the data\ndata = sqlContext.read.options(header='true', inferschema='true').format('csv').load(file_name)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# check the types of data\ndata.cache()\nprint(data.dtypes)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# simple data description\ndisplay(data.describe())"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["We will need a transformer to combine all the features into a single vector. That can be achieved in spark using the `VectorAssembler` library. [VectorAssembler APIs](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler)\n\nHere are some examples for Scala, Java & Python. [Details](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)"],"metadata":{}},{"cell_type":"code","source":["# define the features into a list\nfeatures = [\"temperature\", \"exhaust_vacuum\", \"ambient_pressure\", \"relative_humidity\"]"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# prepare the data\nlr_data = data.select(col(\"energy_output\").alias(\"label\"), \"temperature\", \"exhaust_vacuum\", \"ambient_pressure\", \"relative_humidity\")\nlr_data.printSchema()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# split the dataset into training and test\n(training, test) = lr_data.randomSplit([.7, .3], seed = 196)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# A vector is what the ML algorithm reads to train a model\ntraining_vector = VA(inputCols=features, outputCol=\"features\").transform(training).select(\"label\", \"features\")\ntest_vector     = VA(inputCols=features, outputCol=\"features\").transform(test).select(\"label\", \"features\")"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Create a Linear Regression Model object\nlr = LR()\n\n# Fit the model to the data\nmodel = lr.fit(training_vector)\n\n# We use explain params to dump the parameters we can use\n# print(lr.explainParams())"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# run the model on the test data\nresults = model.transform(test_vector)\n\n# results.show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# evaluate the model\nfrom pyspark.ml.evaluation import RegressionEvaluator as RE\n\n# Root Mean Square Error\neval = RE(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = eval.evaluate(results)\nprint(\"RMSE: %.3f\" % rmse)\n\n# Mean Square Error\nmse = eval.evaluate(results, {eval.metricName: \"mse\"})\nprint(\"MSE: %.3f\" % mse)\n\n# Mean Absolute Error\nmae = eval.evaluate(results, {eval.metricName: \"mae\"})\nprint(\"MAE: %.3f\" % mae)\n\n# r2\nr2 = eval.evaluate(results, {eval.metricName: \"r2\"})\nprint(\"r2: %.3f\" %r2)"],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"LinearRegressionPython","notebookId":1673584615423252},"nbformat":4,"nbformat_minor":0}
