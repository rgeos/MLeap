{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using ![LOGO](http://demo.epigno.systems/python_spark.png)\n",
    "\n",
    "In this notebook we will will employ a simple linear regression model to predict the amount of energy output of a power plant. The dataset used for this analysis comes from UC Irvine [machine learning repository](http://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant). The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011).\n",
    "\n",
    "**Data information** as described on the site above:\n",
    "\n",
    "Features consist of hourly average ambient variables \n",
    "- Temperature (T) in the range 1.81C and 37.11C,\n",
    "- Ambient Pressure (AP) in the range 992.89-1033.30 millibar,\n",
    "- Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "- Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "- Net hourly electrical energy output (EP) 420.26-495.76 MW\n",
    "The averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization.\n",
    "\n",
    "The original headers were renamed as below:\n",
    "- T  -> temperature\n",
    "- V  -> exhaust\\_vacuum\n",
    "- AP -> ambient\\_pressure\n",
    "- RH -> relative\\_humidity\n",
    "- EP -> energy\\_output\n",
    "\n",
    "Our goal is to predict the `energy_output` (label) based on the other four features.\n",
    "\n",
    "Alternative data [Link](http://www.caiso.com/Pages/TodaysOutlook.aspx#SupplyandDemand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression as LR\n",
    "from pyspark.ml.feature import VectorAssembler as VA\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data\n",
    "file_name = \"/FileStore/tables/6zm535q61494044083775/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading the data\n",
    "data = sqlContext.read.options(header='true', inferschema='true').format('csv').load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the types of data\n",
    "data.cache()\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple data description\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a transformer to combine all the features into a single vector. That can be achieved in spark using the `VectorAssembler` library. [VectorAssembler APIs](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler)\n",
    "\n",
    "Here are some examples for Scala, Java & Python. [Details](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the features into a list\n",
    "features = [\"temperature\", \"exhaust_vacuum\", \"ambient_pressure\", \"relative_humidity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "lr_data = data.select(col(\"energy_output\").alias(\"label\"), \"temperature\", \"exhaust_vacuum\", \"ambient_pressure\", \"relative_humidity\")\n",
    "lr_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the dataset into training and test\n",
    "(training, test) = lr_data.randomSplit([.7, .3], seed = 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A vector is what the ML algorithm reads to train a model\n",
    "training_vector = VA(inputCols=features, outputCol=\"features\").transform(training).select(\"label\", \"features\")\n",
    "test_vector     = VA(inputCols=features, outputCol=\"features\").transform(test).select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Linear Regression Model object\n",
    "lr = LR()\n",
    "\n",
    "# Fit the model to the data\n",
    "model = lr.fit(training_vector)\n",
    "\n",
    "# We use explain params to dump the parameters we can use\n",
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the model on the test data\n",
    "results = model.transform(test_vector)\n",
    "\n",
    "# results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator as RE\n",
    "\n",
    "# Root Mean Square Error\n",
    "eval = RE(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = eval.evaluate(results)\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = eval.evaluate(results, {eval.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = eval.evaluate(results, {eval.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2\n",
    "r2 = eval.evaluate(results, {eval.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "LinearRegressionPython",
  "notebookId": 1673584615423252
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
